{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import skopt\n",
    "import talib\n",
    "import pickle\n",
    "import dateutil.relativedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import xgboost as xgb\n",
    "\n",
    "from histDataHandler import loadSuchData\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from binance_historical_data import BinanceDataDumper\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Model name, timeperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelName = \"placeHolderModel\"\n",
    "\n",
    "timePeriods = [2, 5, 30, 2*60, 6*60, 24*60, 4*24*60]\n",
    "rollingMeanWindow = 10\n",
    "predictionHorizon = 11\n",
    "\n",
    "modelParamsDict = {\n",
    "    \"timePeriods\":timePeriods,\n",
    "    \"rollingMeanWindow\":rollingMeanWindow,\n",
    "    \"predictionHorizon\":predictionHorizon,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initialDate = \"2022-01-01\"\n",
    "\n",
    "BTCUSDT_1m = loadSuchData(startDate=initialDate,ticker=\"BTCUSDT\",frequency=\"1m\")\n",
    "\n",
    "BTCUSDT_1m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data functions to be used later in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def splitData(\n",
    "    TrainSize,\n",
    "    ValSize,\n",
    "    TestSize,\n",
    "    blockLengthInDays,\n",
    "    data):\n",
    "    \"\"\"\n",
    "    Split data into Train, Val and Test sets.\n",
    "    The data is split into blocks of blockLengthInDays days.\n",
    "    The data is then split into Train, Val and Test sets.\n",
    "    \"\"\"\n",
    "    totSize = TrainSize+ValSize+TestSize\n",
    "    TrainRatio = TrainSize/totSize\n",
    "    ValRatio = ValSize/totSize\n",
    "    # Test ratio is implicit from totSize\n",
    "\n",
    "    datetimeIndex = data.index\n",
    "\n",
    "    startTimeStamp = datetimeIndex[0]\n",
    "    endTimeStamp = datetimeIndex[-1]\n",
    "    blockLength = dt.timedelta(days=blockLengthInDays)\n",
    "\n",
    "    nBlocks = math.floor((endTimeStamp-startTimeStamp)/blockLength)\n",
    "\n",
    "    Train = pd.DataFrame()\n",
    "    Val = pd.DataFrame()\n",
    "    Test = pd.DataFrame()\n",
    "\n",
    "    for i in range(nBlocks):\n",
    "        TrainStart = endTimeStamp-(i+1)*blockLength\n",
    "        TrainEndValStart = TrainStart + TrainRatio*blockLength\n",
    "        ValEndTestStart = TrainEndValStart + ValRatio*blockLength\n",
    "        TestEnd = endTimeStamp-(i)*blockLength\n",
    "\n",
    "        Train = pd.concat([Train,data[TrainStart:TrainEndValStart]])\n",
    "        Val = pd.concat([Val,data[TrainEndValStart:ValEndTestStart]])\n",
    "        Test = pd.concat([Test,data[ValEndTestStart:TestEnd]])\n",
    "\n",
    "    return Train, Val, Test\n",
    "\n",
    "def splitDataRandom(\n",
    "    TrainSize,\n",
    "    ValSize,\n",
    "    TestSize,\n",
    "    data):\n",
    "    \"\"\"\n",
    "    Split data into Train, Val and Test sets.\n",
    "    Each sample in Train, Val and Test are randomly picked from data\n",
    "    1- randomly pick a sample from data\n",
    "    2- roll a random number between 0 and totSize\n",
    "    3- if the number is smaller than TrainSize, add the sample to Train, else if it is smaller than TrainSize+ValSize, add the sample to Val, else add the sample to Test\n",
    "    4- remove the sample from data so it doesn't get picked again\n",
    "    \"\"\"\n",
    "    totSize = TrainSize+ValSize+TestSize\n",
    "    trainCutOff = TrainSize/totSize\n",
    "    valCutOff = (TrainSize+ValSize)/totSize\n",
    "\n",
    "    # initialize Train, Val and Test\n",
    "    TrainSel = []\n",
    "    ValSel = []\n",
    "    TestSel = []\n",
    "\n",
    "    dataLen = len(data)\n",
    "\n",
    "    #initialize loop\n",
    "    for i in range(dataLen):\n",
    "        # roll random float between 0 and 1\n",
    "        randomRoll = np.random.rand()\n",
    "\n",
    "        # add sample to Train, Val or Test\n",
    "        if randomRoll < trainCutOff:\n",
    "            TrainSel.append(i)\n",
    "        elif randomRoll < valCutOff:\n",
    "            ValSel.append(i)\n",
    "        else:\n",
    "            TestSel.append(i)\n",
    "    \n",
    "    Train = data.iloc[TrainSel]\n",
    "    Val = data.iloc[ValSel]\n",
    "    Test = data.iloc[TestSel]\n",
    "\n",
    "    return Train, Val, Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the target the model will be trained to predict\n",
    "\n",
    "Currently the model will be trained to predict the percentual change in a determined Moving Average (MA)\n",
    "\n",
    "The format is:\n",
    "    \n",
    "        - 1%  Up prediction -> 101\n",
    "    \n",
    "        - 10% Up prediction -> 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genTarget(data, rollingMeanWindow, predictionHorizon):\n",
    "    \"\"\"\n",
    "    Generate target column for prediction.\n",
    "    The target column is the rolling mean of the Close price.\n",
    "    The rolling mean is shifted by predictionHorizon.\n",
    "    \"\"\"\n",
    "    currentMean = talib.MA(data[\"Close\"],timeperiod=rollingMeanWindow)\n",
    "    futureMean = talib.MA(data[\"Close\"],timeperiod=rollingMeanWindow).shift(-predictionHorizon)\n",
    "    # compute percentual difference between current and future mean\n",
    "    target = 100+((futureMean-currentMean)*100/currentMean)\n",
    "    return pd.concat([data,target.rename(\"Target\")],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Date features\n",
    "\n",
    "Process data index to generate datetime features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genDate(data):\n",
    "    \"\"\"\n",
    "    Generate date columns from index.\n",
    "    \"\"\"\n",
    "    data[\"year\"] = data.index.year\n",
    "    data[\"month\"] = data.index.month\n",
    "    data[\"day\"] = data.index.day\n",
    "    data[\"dayofweek\"] = data.index.dayofweek\n",
    "    data[\"hour\"] = data.index.hour\n",
    "    data[\"minute\"] = data.index.minute\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Technical indicators\n",
    "\n",
    "Some sample indicators from talib\n",
    "\n",
    "Edit this session to add or remove indicators to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genBollingerBand(data, timeperiods, colname):\n",
    "    \"\"\"\n",
    "    Generate Bollinger Bands.\n",
    "    \"\"\"\n",
    "    newCols = pd.DataFrame()\n",
    "    for timeperiod in timeperiods:\n",
    "        newCols[\"{}_upper_band_{}m\".format(colname, timeperiod)], newCols[\"{}_middle_band_{}m\".format(colname, timeperiod)], newCols[\"{}_lower_band_{}m\".format(colname, timeperiod)] = talib.BBANDS(data[colname], timeperiod=timeperiod)\n",
    "    return newCols\n",
    "\n",
    "def genRSI(data, timeperiods, colname):\n",
    "    \"\"\"\n",
    "    Generate RSI.\n",
    "    \"\"\"\n",
    "    newCols = pd.DataFrame()\n",
    "    for timeperiod in timeperiods:\n",
    "        newCols[\"{}_rsi_{}m\".format(colname, timeperiod)] = talib.RSI(data[colname], timeperiod=timeperiod)\n",
    "    return newCols\n",
    "\n",
    "def genPercentChange(data, timeperiods, colname):\n",
    "    \"\"\"\n",
    "    Generate percent change.\n",
    "    \"\"\"\n",
    "    newCols = pd.DataFrame()\n",
    "    for timeperiod in timeperiods:\n",
    "        newCols[\"{}_percent_change_{}m\".format(colname, timeperiod)] = data[colname].pct_change(timeperiod)\n",
    "    return newCols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genTechnicalIndicators(data, timeperiods):\n",
    "       \"\"\"\n",
    "       Generate technical indicators.\n",
    "       \"\"\"\n",
    "\n",
    "       # Close\n",
    "       data = pd.concat([data, genBollingerBand(data, timeperiods=timeperiods, colname=\"Close\")], axis=1)\n",
    "       data = pd.concat([data, genRSI(data, timeperiods=timeperiods, colname=\"Close\")], axis=1)\n",
    "       data = pd.concat([data, genPercentChange(data, timeperiods=timeperiods, colname=\"Close\")], axis=1)\n",
    "\n",
    "       #Volume\n",
    "       data = pd.concat([data, genBollingerBand(data, timeperiods=timeperiods, colname=\"Volume\")], axis=1)\n",
    "       data = pd.concat([data, genRSI(data, timeperiods=timeperiods, colname=\"Volume\")], axis=1)\n",
    "       data = pd.concat([data, genPercentChange(data, timeperiods=timeperiods, colname=\"Volume\")], axis=1)\n",
    "\n",
    "       # drop all na and infinite values\n",
    "       data = data.replace([np.inf, -np.inf], np.nan)\n",
    "       data = data.dropna()\n",
    "\n",
    "       return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling functions\n",
    "\n",
    "We are using only MinMaxScaler for now\n",
    "\n",
    "Cyclical features will go through a different process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rescale_gen(data,modelName,save=False):\n",
    "    \"\"\"\n",
    "    Rescale data using MinMaxScaler and save scaler to model folder\n",
    "    \"\"\"\n",
    "    mms = MinMaxScaler()\n",
    "    dir = f\"../models/{modelName}/scalers/\"\n",
    "    # if dir doesnt exist, create it\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    for i in data.columns:\n",
    "        # do not scale cyclical features\n",
    "        # month\tday\tdayofweek\thour\tminute\n",
    "        if (i == \"month\") | (i == \"day\") | (i == \"dayofweek\") | (i == \"hour\") | (i == \"minute\"):\n",
    "            continue\n",
    "        data[i] = mms.fit_transform(data[[i]])\n",
    "        if save: pickle.dump(mms, open(f\"{dir}/{i}_scaler.pkl\", 'wb'))\n",
    "\n",
    "    return data\n",
    "\n",
    "# rescale function to load rescalers from folder and apply them to corresponding columns\n",
    "def rescale_load(data,modelName):\n",
    "    \"\"\"\n",
    "    Rescale data using existing scalers from model folder\n",
    "    \"\"\"\n",
    "    scalers = {}\n",
    "    for i in data.columns:\n",
    "        if (i == \"month\") | (i == \"day\") | (i == \"dayofweek\") | (i == \"hour\") | (i == \"minute\"):\n",
    "            continue\n",
    "\n",
    "        mms = pickle.load(open(f'../models/{modelName}/scalers/{i}_scaler.pkl', 'rb'))\n",
    "        scalers[f\"{i}_scaler\"] = mms\n",
    "        data[i] = mms.transform(data[[i]])\n",
    "\n",
    "    return scalers\n",
    "\n",
    "def descaleFeature(data,modelName,featureName):\n",
    "    \"\"\"\n",
    "    Descale given feature\n",
    "    \"\"\"\n",
    "    mms = pickle.load(open(f'models/{modelName}/scalers/{featureName}_scaler.pkl', 'rb'))\n",
    "    descaledTarget = (mms.inverse_transform(data[[featureName]]))\n",
    "    \n",
    "    return pd.DataFrame(descaledTarget).iloc[:,0].rename(f\"descaled_{featureName}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Nature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give cyclical nature to cyclical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cyclicalTime(data):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    data['month_sin'] = data['month'].apply(lambda x: np.sin(x*(2.*np.pi/12)))\n",
    "    data['month_cos'] = data['month'].apply(lambda x: np.cos(x*(2.*np.pi/12)))\n",
    "\n",
    "    data['day_of_month_sin'] = data['day'].apply(lambda x: np.sin(x*(2.*np.pi/30)))\n",
    "    data['day_of_month_cos'] = data['day'].apply(lambda x: np.cos(x*(2.*np.pi/30)))\n",
    "\n",
    "    data['dayofweek_cos'] = data['dayofweek'].apply(lambda x: np.cos(x*(2.*np.pi/7)))\n",
    "    data['dayofweek_sin'] = data['dayofweek'].apply(lambda x: np.sin(x*(2.*np.pi/7)))\n",
    "\n",
    "    data['hour_sin'] = data['hour'].apply(lambda x: np.sin(x*(2.*np.pi/24)))\n",
    "    data['hour_cos'] = data['hour'].apply(lambda x: np.cos(x*(2.*np.pi/24)))\n",
    "\n",
    "    data['minute_sin'] = data['minute'].apply(lambda x: np.sin(x*(2.*np.pi/60)))\n",
    "    data['minute_cos'] = data['minute'].apply(lambda x: np.cos(x*(2.*np.pi/60)))\n",
    "\n",
    "    # drop month, day, dayofweek, hour and minute columns from data\n",
    "    data = data.drop(['month','day','dayofweek','hour','minute'], axis=1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Apply functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apply all previously defined functions to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"generating target\")\n",
    "BTCUSDT_1m = genTarget(data=BTCUSDT_1m, rollingMeanWindow=rollingMeanWindow, predictionHorizon=predictionHorizon)\n",
    "\n",
    "print(\"generating date features\")\n",
    "BTCUSDT_1m = genDate(BTCUSDT_1m)\n",
    "\n",
    "print(\"generating technical indicators\")\n",
    "BTCUSDT_1m = genTechnicalIndicators(BTCUSDT_1m,timePeriods)\n",
    "\n",
    "print(\"rescaling\")\n",
    "BTCUSDT_1m = rescale_gen(BTCUSDT_1m,modelName=modelName,save=True)\n",
    "\n",
    "print(\"generating cyclical features\")\n",
    "BTCUSDT_1m = cyclicalTime(BTCUSDT_1m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Error functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define error functions to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_percentage_error(y, yhat):\n",
    "    return np.mean( (y-yhat)/y)\n",
    "     \n",
    "def mean_absolute_percentage_error(y, yhat):\n",
    "    return np.mean( np.abs((y-yhat)/y))\n",
    "\n",
    "def smape_error(y, yhat):\n",
    "  \n",
    "    # Convert actual and predicted to numpy\n",
    "    # array data type if not already\n",
    "    if not all([isinstance(y, np.ndarray),isinstance(yhat, np.ndarray)]):\n",
    "        y, yhat = np.array(y),np.array(yhat)\n",
    "  \n",
    "    return round(np.mean(np.abs(yhat - y) / ((np.abs(yhat) + np.abs(y))/2))*100, 4)\n",
    "\n",
    "def rmse_error(y, yhat):\n",
    "    return np.sqrt( mean_squared_error(y, yhat))\n",
    "\n",
    "def ml_error(model_name, y, yhat):\n",
    "    # when y or yhat is negative, give them 0 value\n",
    "    y = np.where(y < 0, 0, y)\n",
    "    yhat = np.where(yhat < 0, 0, yhat)\n",
    "\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    smape = smape_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y, yhat)\n",
    "    rmse = rmse_error(y, yhat)\n",
    "    msle = mean_squared_log_error(y, yhat, squared=True)\n",
    "    rmsle = mean_squared_log_error(y, yhat, squared=False)\n",
    "    \n",
    "    return pd.DataFrame( { 'Model Name': model_name, \n",
    "                           'MAE': mae,\n",
    "                           'SMAPE': smape,\n",
    "                           'MAPE': mape,\n",
    "                           'RMSE': rmse,\n",
    "                           \"MSLE\" : msle,\n",
    "                           'RMSLE': rmsle\n",
    "                           },index=[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally split the data using function from 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train, Val, Test = splitDataRandom(TrainSize=0.84,ValSize=0.08,TestSize=0.08,data=BTCUSDT_1m)\n",
    "\n",
    "x_train = Train.drop([\"Target\"],axis=1)\n",
    "y_train = Train[\"Target\"]\n",
    "\n",
    "x_val = Val.drop([\"Target\"],axis=1)\n",
    "y_val = Val[\"Target\"]\n",
    "\n",
    "x_test = Test.drop([\"Target\"],axis=1)\n",
    "y_test = Test[\"Target\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Hyperparameter finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skopt.gp_minize to speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(params):\n",
    "    learning_rate = params[0]\n",
    "    subsample = params[1]\n",
    "    colsample_bytree = params[2]\n",
    "    max_depth = params[3]\n",
    "    print(params)\n",
    "    model_xgb = xgb.XGBRegressor(\n",
    "        eta=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        max_depth =max_depth,\n",
    "        tree_method='gpu_hist',\n",
    "        predictor=\"gpu_predictor\",\n",
    "    )\n",
    "    model_xgb.fit(x_train, y_train)\n",
    "    yhat = model_xgb.predict(x_val)\n",
    "    error = rmse_error(y_val, yhat)\n",
    "    print(f\"ERROR: {error}\")\n",
    "    return error\n",
    "\n",
    "space = [\n",
    "        (.001, .5, 'log-uniform'), #learning rate\n",
    "        (0.2, 1.0),    # subsample         \n",
    "        (0.1, 1.0),     # colsample bytree  \n",
    "        (5, 10)         # max_depth         \n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_gp = skopt.gp_minimize(train_model, space, random_state=42, verbose=1, n_calls=40, n_random_starts=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = results_gp.x\n",
    "\n",
    "params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a couple different models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = params[0]\n",
    "subsample = params[1]\n",
    "colsample_bytree = params[2]\n",
    "max_depth = params[3]\n",
    "\n",
    "model_xgb_bayes = xgb.XGBRegressor(\n",
    "        eta=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        max_depth =max_depth,\n",
    "        tree_method='gpu_hist',\n",
    "        predictor=\"gpu_predictor\",\n",
    "    )\n",
    "model_xgb_default = xgb.XGBRegressor(\n",
    "        tree_method='gpu_hist',\n",
    "        predictor=\"gpu_predictor\",\n",
    "    )\n",
    "model_linear_regression = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeModelErrors(model, resultsName, x_train, y_train, x_test, y_test):\n",
    "    modelFit = model.fit(x_train, y_train)\n",
    "    yhat = modelFit.predict(x_test)\n",
    "    return ml_error(resultsName, y_test, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgboost_bayes_result = computeModelErrors(model_xgb_bayes, \"XGBoost Bayes\", x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgboost_default_result = computeModelErrors(model_xgb_default, \"XGBoost Default\", x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_result = computeModelErrors(model_linear_regression, \"Linear\", x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.concat([\n",
    "    xgboost_bayes_result,\n",
    "    xgboost_default_result,\n",
    "    linear_result,\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Save selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save model to folder for use in trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_all = BTCUSDT_1m.drop([\"Target\"],axis=1)\n",
    "y_all = BTCUSDT_1m[\"Target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def saveModel(model, modelName, modelParamsDict):\n",
    "    with open( f\"../models/{modelName}/{modelName}.pkl\", 'wb' ) as file:\n",
    "        pickle.dump( model, file )\n",
    "    # save model params dict to same folder\n",
    "    with open( f\"../models/{modelName}/{modelName}_params.json\", 'w' ) as file:\n",
    "        json.dump( modelParamsDict, file )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selectedModel = model_xgb_bayes.fit(x_all, y_all)\n",
    "saveModel(selectedModel, modelName, modelParamsDict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('liveBot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "101e8320b3bd7676b1f6ebaca0f575302d5be34029f5123ea14c6d79a79f127e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
